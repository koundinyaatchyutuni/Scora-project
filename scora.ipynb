{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f886289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: asttokens==2.2.1 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: backcall==0.2.0 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: click==8.1.3 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 3)) (8.1.3)\n",
      "Requirement already satisfied: colorama==0.4.6 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 4)) (0.4.6)\n",
      "Requirement already satisfied: comm==0.1.2 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 5)) (0.1.2)\n",
      "Requirement already satisfied: debugpy==1.6.6 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 6)) (1.6.6)\n",
      "Requirement already satisfied: decorator==5.1.1 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 7)) (5.1.1)\n",
      "Requirement already satisfied: et-xmlfile==1.1.0 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: executing==1.2.0 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: Flask==2.2.2 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 10)) (2.2.2)\n",
      "Requirement already satisfied: importlib-metadata==5.0.0 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 11)) (5.0.0)\n",
      "Requirement already satisfied: ipykernel==6.21.3 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 12)) (6.21.3)\n",
      "Requirement already satisfied: ipython==8.11.0 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 13)) (8.11.0)\n",
      "Requirement already satisfied: itsdangerous==2.1.2 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 14)) (2.1.2)\n",
      "Requirement already satisfied: jedi==0.18.2 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 15)) (0.18.2)\n",
      "Requirement already satisfied: Jinja2==3.1.2 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 16)) (3.1.2)\n",
      "Requirement already satisfied: joblib==1.2.0 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 17)) (1.2.0)\n",
      "Requirement already satisfied: jupyter_client==8.0.3 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 18)) (8.0.3)\n",
      "Requirement already satisfied: jupyter_core==5.3.0 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 19)) (5.3.0)\n",
      "Requirement already satisfied: MarkupSafe==2.1.1 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 20)) (2.1.1)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 21)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 22)) (1.5.6)\n",
      "Requirement already satisfied: nltk==3.8.1 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 23)) (3.8.1)\n",
      "Requirement already satisfied: numpy==1.21.4 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 24)) (1.21.4)\n",
      "Requirement already satisfied: openpyxl==3.0.10 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 25)) (3.0.10)\n",
      "Requirement already satisfied: packaging==23.0 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 26)) (23.0)\n",
      "Requirement already satisfied: pandas==1.5.2 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 27)) (1.5.2)\n",
      "Requirement already satisfied: parso==0.8.3 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 28)) (0.8.3)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 29)) (0.7.5)\n",
      "Requirement already satisfied: platformdirs==3.1.1 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 30)) (3.1.1)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.38 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 31)) (3.0.38)\n",
      "Requirement already satisfied: psutil==5.9.4 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 32)) (5.9.4)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 33)) (0.2.2)\n",
      "Requirement already satisfied: pycryptodome==3.16.0 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 34)) (3.16.0)\n",
      "Requirement already satisfied: Pygments==2.14.0 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 35)) (2.14.0)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 36)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2022.6 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 37)) (2022.6)\n",
      "Requirement already satisfied: pywin32==305 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 38)) (305)\n",
      "Requirement already satisfied: pyzmq==25.0.1 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 39)) (25.0.1)\n",
      "Requirement already satisfied: regex==2022.10.31 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 40)) (2022.10.31)\n",
      "Requirement already satisfied: six==1.16.0 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 41)) (1.16.0)\n",
      "Requirement already satisfied: stack-data==0.6.2 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 42)) (0.6.2)\n",
      "Requirement already satisfied: tornado==6.2 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 43)) (6.2)\n",
      "Requirement already satisfied: tqdm==4.65.0 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 44)) (4.65.0)\n",
      "Requirement already satisfied: traitlets==5.9.0 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 45)) (5.9.0)\n",
      "Requirement already satisfied: wcwidth==0.2.6 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 46)) (0.2.6)\n",
      "Requirement already satisfied: Werkzeug==2.2.2 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 47)) (2.2.2)\n",
      "Requirement already satisfied: zipp==3.10.0 in c:\\users\\my pc\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 48)) (3.10.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: C:\\Users\\MY PC\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99e8a4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\MY\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package brown to C:\\Users\\MY\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\MY\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\MY\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: rake_nltk in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (1.0.6)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from rake_nltk) (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk<4.0.0,>=3.6.2->rake_nltk) (0.4.6)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pke in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (2.0.0)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (from pke) (3.7)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from pke) (1.0.2)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from pke) (1.1.0)\n",
      "Requirement already satisfied: unidecode in c:\\programdata\\anaconda3\\lib\\site-packages (from pke) (1.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from pke) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from pke) (1.9.1)\n",
      "Requirement already satisfied: spacy>=3.2.3 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from pke) (3.5.0)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from pke) (0.18.2)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from pke) (2.8.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke) (5.2.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy>=3.2.3->pke) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy>=3.2.3->pke) (1.0.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy>=3.2.3->pke) (2.4.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke) (2.28.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke) (2.11.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy>=3.2.3->pke) (1.10.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy>=3.2.3->pke) (3.0.12)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy>=3.2.3->pke) (1.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy>=3.2.3->pke) (2.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy>=3.2.3->pke) (2.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke) (4.64.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy>=3.2.3->pke) (0.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke) (21.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy>=3.2.3->pke) (8.1.7)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy>=3.2.3->pke) (63.4.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy>=3.2.3->pke) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy>=3.2.3->pke) (3.0.8)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from spacy>=3.2.3->pke) (0.10.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->pke) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->pke) (2022.7.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->pke) (2.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy>=3.2.3->pke) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy>=3.2.3->pke) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.3->pke) (3.3)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.3->pke) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.3->pke) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy>=3.2.3->pke) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy>=3.2.3->pke) (2.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement multipartiterank (from versions: none)\n",
      "ERROR: No matching distribution found for multipartiterank\n",
      "C:\\Users\\MY PC\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('brown')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pke\n",
    "import traceback\n",
    "from flashtext import KeywordProcessor\n",
    "# import sys\n",
    "# !pip install rake_nltk\n",
    "from rake_nltk import Rake\n",
    "# !pip install pke\n",
    "# !pip install multipartiterank\n",
    "\n",
    "# sys.path.append('pke-master/pke-master/pke/unsupervised/graph_based')\n",
    "# from multipartiterank import MultipartiteRank\n",
    "\n",
    "class prep:\n",
    "    data=pd.read_csv(\"OS_dataset - Dataset.csv\")\n",
    "    def search_word(self,sentence, word):\n",
    "        sentence_lower = sentence.lower()\n",
    "        word_lower = word.lower()\n",
    "        if word_lower in sentence_lower:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "#     lis=data['Topic']\n",
    "#     w=\"os\"\n",
    "#     indi=[]\n",
    "#     i=0\n",
    "#     for t in lis:\n",
    "#         if search_word(t,w):\n",
    "#             indi.append(i)\n",
    "#         i=i+1\n",
    "            \n",
    "    summary_model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "    summary_tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    summary_model = summary_model.to(device)\n",
    "    \n",
    "    def postprocesstext(self,content):\n",
    "        final=\"\"\n",
    "        for sent in sent_tokenize(content):\n",
    "            sent = sent.capitalize()\n",
    "            final = final +\" \"+sent\n",
    "        return final\n",
    "    \n",
    "    def summarizer(self,text,model,tokenizer):\n",
    "        text = text.strip().replace(\"\\n\",\" \")\n",
    "        text = \"summarize: \"+text\n",
    "        # print (text)\n",
    "        max_len = 512\n",
    "        encoding = tokenizer.encode_plus(text,max_length=max_len, pad_to_max_length=False,truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "        outs = model.generate(input_ids=input_ids,\n",
    "                                        attention_mask=attention_mask,\n",
    "                                        early_stopping=True,\n",
    "                                        num_beams=3,\n",
    "                                        num_return_sequences=1,\n",
    "                                        no_repeat_ngram_size=2,\n",
    "                                        min_length = 75,\n",
    "                                        max_length=300)\n",
    "        dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
    "        summary = dec[0]\n",
    "        summary = self.postprocesstext(summary)\n",
    "        summary= summary.strip()\n",
    "        return summary\n",
    "   \n",
    "   \n",
    "    def get_keywords(self,text):\n",
    "#     text='Natural Language Generation (NLG) is a branch of artificial intelligence (AI) and natural language processing (NLP) that focuses on generating human-like text or speech based on given input or data. NLG algorithms aim to produce coherent, contextually relevant, and linguistically appropriate output that resembles human-generated language.NLG systems utilize various techniques and approaches to generate text. These may include rule-based systems, statistical models, or more advanced deep learning architectures such as recurrent neural networks (RNNs) and transformer models like GPT (Generative Pre-trained Transformer). These models learn from large amounts of text data to capture patterns, semantics, and stylistic nuances in language.'\n",
    "        r=Rake(punctuations=[')','(',',','.',':',').','),'])\n",
    "        r.extract_keywords_from_text(text)\n",
    "    #     print(r.get_ranked_phrases_with_scores())\n",
    "        implist=[]\n",
    "        for rating,keyword in r.get_ranked_phrases_with_scores():\n",
    "            if rating>=4:\n",
    "                implist.append(keyword)\n",
    "        return implist \n",
    "    def m(self):\n",
    "        question_model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
    "#         question_model = question_model\n",
    "        return question_model\n",
    "    def l(self):\n",
    "        question_tokenizer = T5Tokenizer.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
    "        return question_tokenizer\n",
    "    \n",
    "    \n",
    "    def get_question(self,context,answer,model,tokenizer):\n",
    "        text = \"context: {} answer: {}\".format(context,answer)\n",
    "        encoding = tokenizer.encode_plus(text,max_length=384, pad_to_max_length=False,truncation=True, return_tensors=\"pt\")\n",
    "        input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "        outs = model.generate(input_ids=input_ids,\n",
    "                                        attention_mask=attention_mask,\n",
    "                                        early_stopping=True,\n",
    "                                        num_beams=5,\n",
    "                                        num_return_sequences=1,\n",
    "                                        no_repeat_ngram_size=2,\n",
    "                                        max_length=72)\n",
    "        dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
    "        Question = dec[0].replace(\"question:\",\"\")\n",
    "        Question= Question.strip()\n",
    "        return Question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab540df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82825f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "59d69066",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(obj,open('test.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44012ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pickle.load(open('test.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ff01561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.search_word(\"hello h r u\",\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "80f81d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.read_csv(\"OS_dataset - Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4aa649fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hello'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.postprocesstext(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e31a4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "que=x.m()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14eec5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qt=x.l()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f45876e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our tutorial is designed for beginners, professionals and gate aspirants. The content is described in detailed manner and has the ability to answer most of your queries.the tutorial also contains the numerical examples based on previous year gate questions which will help you to address the problems in a practical manner.the operating system tutorial has been divided into various parts depending on its functions such as process management, process synchronization, deadlocks and file management.\n",
      "What is the operating system tutorial divided into?\n",
      "What are the numerical examples based on?\n",
      "What is the main function of the operating system tutorial?\n",
      "How is the operating system tutorial divided?\n",
      "What does the operating system tutorial help you to do?\n",
      "What kind of examples does the operating system tutorial contain?\n",
      "What numerical examples does the operating system tutorial contain?\n",
      "What part of the operating system tutorial has been divided into various parts?\n",
      "What has been divided into various parts depending on its functions?\n",
      "What has been divided into various parts depending on its functions?\n",
      "What has been divided into various parts depending on its functions?\n",
      "What has been divided into various parts depending on its functions?\n",
      "What has been divided into various parts depending on its functions?\n",
      "What has been divided into various parts depending on its functions?\n",
      "What has been divided into various parts depending on its functions?\n",
      "The operating system tutorial has been divided into various parts depending on what function?\n",
      "What is a computer system?\n",
      "What type of tutorial has been divided into various parts?\n",
      "What type of tutorial has been divided into various parts?\n",
      "What type of tutorial has been divided into various parts?\n",
      "What type of tutorial has been divided into various parts?\n",
      "What type of tutorial has been divided into various parts?\n",
      "What type of tutorial has been divided into various parts?\n",
      "What type of tutorial has been divided into various parts?\n",
      "The operating system tutorial is designed for beginners, professionals and who else?\n",
      "The operating system tutorial is designed for beginners, professionals and who else?\n",
      "The operating system tutorial has been divided into various parts depending on what?\n",
      "What is one function of the operating system tutorial?\n",
      "Along with deadlocks and file management, what is one function of the operating system tutorial?\n",
      "Along with deadlocks and file management, what is one function of the operating system tutorial?\n",
      "The numerical examples will help you to address the problems in what manner?\n",
      "Along with process synchronization, deadlocks and process management, what is an example of an operating system function?\n",
      "Along with process synchronization, deadlocks and process management, what is an example of an operating system function?\n",
      "What does the operating system tutorial do?\n",
      "What is covered in the operating system tutorial?\n",
      "How is the content of the operating system tutorial described?\n",
      "How is the content of our gate tutorial described?\n",
      "What kind of research does the operating system tutorial require?\n",
      "Along with process synchronization, deadlocks and file management, what is one function of the operating system tutorial?\n",
      "What type of topics are covered in the operating system tutorial?\n"
     ]
    }
   ],
   "source": [
    "text=d['Text'][0]\n",
    "word=\"os\"\n",
    "summarized_text = x.summarizer(text,x.summary_model,x.summary_tokenizer)\n",
    "print(summarized_text)\n",
    "imp_keywords = x.get_keywords(text)\n",
    "for answer in imp_keywords:\n",
    "    ques = x.get_question(summarized_text,answer,que,qt)\n",
    "    print(ques)\n",
    "#     questins.append(ques)\n",
    "#     answers.append(answer.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c20d9736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting rake_nltk\n",
      "  Using cached rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from rake_nltk) (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk<4.0.0,>=3.6.2->rake_nltk) (0.4.6)\n",
      "Installing collected packages: rake_nltk\n",
      "Successfully installed rake_nltk-1.0.6\n",
      "[(32.75, 'may include rule - based systems'), (24.75, 'generative pre - trained transformer'), (23.5, 'nlg systems utilize various techniques'), (23.25, 'resembles human - generated language'), (22.75, 'generating human - like text'), (16.0, 'advanced deep learning architectures'), (15.666666666666666, 'transformer models like gpt'), (9.0, 'recurrent neural networks'), (9.0, 'nlg algorithms aim'), (9.0, 'natural language processing'), (9.0, 'natural language generation'), (9.0, 'linguistically appropriate output'), (6.0, 'speech based'), (5.0, 'generate text'), (4.666666666666666, 'statistical models'), (4.666666666666666, 'models learn'), (4.5, 'text data'), (4.0, 'stylistic nuances'), (4.0, 'produce coherent'), (4.0, 'large amounts'), (4.0, 'given input'), (4.0, 'contextually relevant'), (4.0, 'capture patterns'), (4.0, 'artificial intelligence'), (3.0, 'nlg'), (3.0, 'language'), (1.5, 'data'), (1.0, 'semantics'), (1.0, 'rnns'), (1.0, 'nlp'), (1.0, 'focuses'), (1.0, 'branch'), (1.0, 'approaches'), (1.0, 'ai')]\n",
      "may include rule - based systems\n",
      "generative pre - trained transformer\n",
      "nlg systems utilize various techniques\n",
      "resembles human - generated language\n",
      "generating human - like text\n",
      "advanced deep learning architectures\n",
      "transformer models like gpt\n",
      "recurrent neural networks\n",
      "nlg algorithms aim\n",
      "natural language processing\n",
      "natural language generation\n",
      "linguistically appropriate output\n",
      "speech based\n",
      "generate text\n",
      "statistical models\n",
      "models learn\n",
      "text data\n",
      "stylistic nuances\n",
      "produce coherent\n",
      "large amounts\n",
      "given input\n",
      "contextually relevant\n",
      "capture patterns\n",
      "artificial intelligence\n",
      "['may include rule - based systems', 'generative pre - trained transformer', 'nlg systems utilize various techniques', 'resembles human - generated language', 'generating human - like text', 'advanced deep learning architectures', 'transformer models like gpt', 'recurrent neural networks', 'nlg algorithms aim', 'natural language processing', 'natural language generation', 'linguistically appropriate output', 'speech based', 'generate text', 'statistical models', 'models learn', 'text data', 'stylistic nuances', 'produce coherent', 'large amounts', 'given input', 'contextually relevant', 'capture patterns', 'artificial intelligence']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "def get_keywords(text):\n",
    "#     text='Natural Language Generation (NLG) is a branch of artificial intelligence (AI) and natural language processing (NLP) that focuses on generating human-like text or speech based on given input or data. NLG algorithms aim to produce coherent, contextually relevant, and linguistically appropriate output that resembles human-generated language.NLG systems utilize various techniques and approaches to generate text. These may include rule-based systems, statistical models, or more advanced deep learning architectures such as recurrent neural networks (RNNs) and transformer models like GPT (Generative Pre-trained Transformer). These models learn from large amounts of text data to capture patterns, semantics, and stylistic nuances in language.'\n",
    "    r=Rake(punctuations=[')','(',',','.',':',').','),'])\n",
    "    r.extract_keywords_from_text(text)\n",
    "#     print(r.get_ranked_phrases_with_scores())\n",
    "    implist=[]\n",
    "    for rating,keyword in r.get_ranked_phrases_with_scores():\n",
    "        if rating>=4:\n",
    "            implist.append(keyword)\n",
    "    return implist        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_nouns_multipartite(self,content):\n",
    "        out=[]\n",
    "        try:\n",
    "            extractor = MultipartiteRank()\n",
    "            extractor.load_document(input=content,language='en')\n",
    "            pos = {'PROPN','NOUN'}\n",
    "            stoplist = list(string.punctuation)\n",
    "            stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
    "            stoplist += stopwords.words('english')\n",
    "            extractor.candidate_selection(pos=pos)\n",
    "            extractor.candidate_weighting(alpha=1.1,\n",
    "                                        threshold=0.75,\n",
    "                                        method='average')\n",
    "            keyphrases = extractor.get_n_best(n=15)\n",
    "            for val in keyphrases:\n",
    "                out.append(val[0])\n",
    "        except:\n",
    "            out = []\n",
    "            traceback.print_exc()\n",
    "        return out\n",
    "    \n",
    "    def get_keywords(self,originaltext,summarytext):\n",
    "        keywords = self.get_nouns_multipartite(originaltext)\n",
    "        print (\"keywords unsummarized: \",keywords)\n",
    "        keyword_processor = KeywordProcessor()\n",
    "        for keyword in keywords:\n",
    "            keyword_processor.add_keyword(keyword)\n",
    "        keywords_found = keyword_processor.extract_keywords(summarytext)\n",
    "        keywords_found = list(set(keywords_found))\n",
    "        print (\"keywords_found in summarized: \",keywords_found)\n",
    "        important_keywords =[]\n",
    "        for keyword in keywords:\n",
    "            if keyword in keywords_found:\n",
    "                important_keywords.append(keyword)\n",
    "        return important_keywords[:4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
